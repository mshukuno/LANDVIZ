# LANDIS-II-Visualization
# PreProc Tool patch
# Tool data preparation
# 08/31/2020
# Makiko Shukunobe, Center for Geospatial Analytics, North Carolina State University

import os
import logging
import lxml.etree as etree
import yaml
from xmldiff import main
import pandas as pd
import csv
import app_settings

# Merge function XML path
XML_ROOT_TAG = 'Catalog'
XML_META_WRAPPER_TAG = 'Scenario'
ATTRIB_NAME = 'name'
ATTRIB_XMLPATH = 'xmlPath'
PARENT_ATTRIB_XMLPATH = 'xmlPath'
PREPROCESS_XML_NAME = 'LANDIS II: XML Configuration Tool'

# LANDIS II metadata root XML path name
LANDISMETADATA_TAG = 'landisMetadata'

logger = logging.getLogger(__name__)


def loadYamlConfig(appPath, configYaml):
    """
    Load Yaml configuration file.
    @param str appPath: This application file path
    @param configYaml: ConfigYaml file path
    @return dict: Dictionary generated from "configYaml" file
    """
    try:
        # load YAML CONFIG File
        with open(os.path.join(appPath, configYaml), 'r') as f:
            return yaml.load(f, Loader=yaml.FullLoader)

    except Exception as e:
        app_settings.error_log(logger, e)


def checkConfigXml(tree):
    """
    Check input configuration XML file is generated by the PreProc
    "merge" tool.
    @param ElementTree tree: ConfigXML tree object
    @return:
    """
    try:
        if tree.tag == XML_ROOT_TAG:
            if tree.attrib['name'] == PREPROCESS_XML_NAME:
                return True
        else:
            raise ValueError

    except ValueError:
        logger.error('Configuration XML does not match the schema.')
    except Exception as e:
        app_settings.error_log(logger, e)


def writeXml(xmlFile, newTree, oldTree):
    """
    I/O output
    @param str xmlFile: XML file path
    @param ElementTree newTree: Modified XML
    @param ElementTree oldTree: Original XML
    """
    try:
        with open(xmlFile, 'w') as f:
            f.write(etree.tostring(newTree).decode('utf-8'))

    except Exception as e:
        logger.error('Rollback to original')
        with open(xmlFile, 'w') as f:
            f.write(etree.tostring(oldTree).decode('utf-8'))
        app_settings.error_log(logger, e)


class PreProcess(object):
    def __init__(self, appPath, configYaml, args):
        """
        merge and update functions
        @param str appPath: PreProcTool file path
        @param str configYaml: PreProcTool application configuration file
        @param Namespace object args: User inputs
        """
        self.projectFile = args.projectFile
        self.configFile = args.configFile
        self.CONFIG = loadYamlConfig(appPath, configYaml)

    def getProjectXml(self, projectFile):
        """
        Get project XML files for project scenario lists.
        @param str projectFile: Project file path
        @return List[str] projectScenarios: A list of name of scenarios
        """
        try:
            projectScenarios = []
            parser = etree.XMLParser(remove_blank_text=True)
            tree = etree.parse(projectFile, parser).getroot()
            scenarios = tree.xpath(self.CONFIG['XPATH']['SCENARIOLIST'])

            if scenarios:
                # catalog = etree.Element(XML_ROOT_TAG, name=PREPROCESS_XML_NAME)
                for scenario in scenarios:
                    projectScenarios.append(scenario.attrib[self.CONFIG['ATTRIB']['SCENARIOPATH']])
                if len(projectScenarios) == 1:
                    logger.info('[1] scenario')
                elif len(projectScenarios) > 0:
                    logger.info(f'[{len(projectScenarios)}] scenarios')
                return projectScenarios
            else:
                raise ValueError

        except ValueError:
            logger.error('No "scenario" XML tag found in file.')
        except Exception as e:
            app_settings.error_log(logger, e)

    def mergeXMLs(self):
        """
        Merge extension metadata XML files.
        """
        try:
            # Get project XML file directory - result output file will be saved there.
            projectFileBase = os.path.dirname(self.projectFile)
            resultXml = os.path.join(projectFileBase, self.configFile)

            # Get senario directory
            projectScenarios = self.getProjectXml(self.projectFile)

            # LXML settings
            parser = etree.XMLParser(remove_blank_text=True)
            catalog = etree.Element(XML_ROOT_TAG, name=PREPROCESS_XML_NAME)

            totalXmlCounter = 0
            # ForEach scenario get extension XML file
            # THEN 
            # * convert XML content to ElementTree object
            # * append it to "Catalog" ElementTree object   
            for scenario in projectScenarios:
                xmlFileCounter = 0
                metadataPath = os.path.join(projectFileBase, scenario,
                                            self.CONFIG['METADATA']['DIR'])
                if os.path.isdir(metadataPath):
                    for root, dirs, files in os.walk(metadataPath):
                        for f in files:
                            xmlFullPath = os.path.join(root, f)
                            nsXmlPath = xmlFullPath.split(scenario)[1]
                            # New element
                            project = etree.Element(XML_META_WRAPPER_TAG,
                                                    name=scenario, xmlPath=nsXmlPath)
                            # Convert xml file to ElementTree
                            xmlContent = etree.parse(xmlFullPath, parser).getroot()
                            project.append(xmlContent)
                            catalog.append(project)
                            xmlFileCounter += 1
                    logger.info(f'{scenario}: [{xmlFileCounter}] XML files')
                    totalXmlCounter += xmlFileCounter
            # Write the ElenmentTree object to file 

            with open(resultXml, 'wb') as f:
                f.write(b'<?xml version="1.0" encoding="UTF-8"?>\n')
                f.write(etree.tostring(catalog, pretty_print=True))

            logger.info(f'[{totalXmlCounter}] XML files merged')
            logger.info('Merge complete')

        except Exception as e:
            app_settings.error_log(logger, e)

    def updateXMLs(self):
        """
        Update extension metadata XMLs according metadata configuration.
        """
        parser = etree.XMLParser(remove_blank_text=True)
        # formatter = formatting.XmlDiffFormatter(normalize=formatting.WS_NONE)
        try:
            # Get senario directory
            projectScenarios = self.getProjectXml(self.projectFile)
            projectFileBase = os.path.dirname(self.projectFile)
            #             print(projectFileBase)
            configXml = os.path.join(projectFileBase, self.configFile)
            tree = etree.parse(configXml, parser).getroot()

            if checkConfigXml(tree):
                diffCounter = 0
                # ForEach 'Scenario' tag
                for scenario in tree.findall(XML_META_WRAPPER_TAG):
                    # Get 'name' attribute text
                    scenarioName = ''
                    xmlPath = ''
                    # if scenario.attrib.has_key(ATTRIB_NAME):
                    if ATTRIB_NAME in scenario.attrib:
                        scenarioName = scenario.attrib[ATTRIB_NAME]
                    #                 print(scenario_name)
                    # Get 'xmlPath' attribute text
                    # if scenario.attrib.has_key(ATTRIB_XMLPATH):
                    if ATTRIB_XMLPATH in scenario.attrib:
                        xmlPath = scenario.attrib[ATTRIB_XMLPATH]

                    # IF 'Scenario' tag has 'name' and 'xmlPath' attributes
                    if len(scenarioName) > 0 and len(xmlPath) > 0:
                        if scenarioName in projectScenarios:
                            # print(scenarioName, xmlPath)
                            # Get original XML file
                            xmlFile = f'{projectFileBase}\\{scenarioName}\\{xmlPath}'
                            # Parse target XML file
                            oldTree = etree.parse(xmlFile, parser)
                            # Get 'landisMetadata' tag elements
                            landisMeta = scenario.xpath(LANDISMETADATA_TAG)[0]
                            newTree = etree.ElementTree(landisMeta)

                            diffs = main.diff_trees(oldTree, newTree)

                            if len(diffs) > 0:
                                logger.info(f'\n[{len(diffs)}] updates on \
                                    {os.path.join(scenarioName, xmlPath)}')
                                for idx, diff in enumerate(diffs):
                                    diffCounter += 1
                                    logger.info(f'{idx + 1}: {diff}')

                                writeXml(xmlFile, newTree, oldTree)

                if diffCounter == 0:
                    logger.info('No updates')

        except Exception as e:
            app_settings.error_log(logger, e)


class ExtensionLog(object):
    def __init__(self, args):
        """
        Adds missing time steps to a extension log CSV file.
        @param Namespace object args: User inputs
        """
        self.csv_log_file = args.csv_log_file
        self.out_csv_log_file = args.out_csv_log_file
        self.time_step_column = args.time_step_column
        self.time_interval = args.time_interval
        self.min_time = args.min_time
        self.max_time = args.max_time
        self.group_by_column = args.group_by_column

    def output_file_path(self, file_name):
        """
        Add .csv extension if doesn't have one.
        @return str out_file_path: Output CSV file path
        """
        try:
            in_csv_dir = os.path.dirname(self.csv_log_file)
            in_csv_file_name = os.path.basename(self.csv_log_file).split('.')[0]
            out_csv_file_name = file_name.split('.')[0]

            if in_csv_file_name.lower() == out_csv_file_name.lower():
                raise ValueError
            else:
                out_file_path = os.path.join(in_csv_dir, out_csv_file_name + '.csv')
                return out_file_path

        except ValueError:
            logger.error('Input CSV file name and output file name is the same. Change output file name.')
        except Exception as e:
            app_settings.error_log(logger, e)

    def out_csv(self, data):
        """
        Write data to CSV file.
        @param List[dict] data: The data with all missing steps.
        """
        try:
            logger.info('Write data to CSV file.')
            keys = data[0].keys()
            out_log = self.output_file_path(self.out_csv_log_file)

            if out_log:
                with open(out_log, 'w', newline='') as output_file:
                    dict_writer = csv.DictWriter(output_file, keys)
                    dict_writer.writeheader()
                    dict_writer.writerows(data)
                logger.info(f'{out_log} created.')

        except Exception as e:
            app_settings.error_log(logger, e)

    def add_time_steps(self, df, time_steps):
        """
        Add missing time steps (no groupby query).
        @param DataFrame df: a DataFrame object created from a CSV file.
        @param List[int] time_steps: all time steps.
        @return List[dict] data: data time steps.
        """
        try:
            logger.info('Add time steps (no groupby query.')
            data = []
            data_time_steps = list(df[self.time_step_column])

            if set(time_steps) != set(data_time_steps):
                logger.info('Found missing time steps.')
                for step in time_steps:
                    if step not in data_time_steps:
                        row = {field: 0 for field in list(df.columns)}
                        row[self.time_step_column] = step
                    else:
                        row = df.query(f'{self.time_step_column} == {step}').to_dict('records')[0]
                    data.append(row)
                return data
            else:
                logger.info('No missing time steps.')

        except Exception as e:
            app_settings.error_log(logger, e)

    def add_time_steps_groupby(self, df, time_steps):
        """
        Add missing time steps (groupby query).
        @param DataFrame df: a DataFrame object created from a CSV file.
        @param List[int] time_steps: all time steps.
        @return List[dict] data: data time steps.
        """
        try:
            logger.info('Add time steps using group by query.')
            names = df[self.group_by_column].unique()
            data = []
            contain_space = False

            for name in names:
                select_by_name_df = df.query(f'{self.group_by_column} == "{name}"').sort_values(
                    by=self.time_step_column)
                # Remove a space at zero (e.g. '  SpruceBudworm')
                if name.startswith(' '):
                    contain_space = True
                    select_by_name_df[self.group_by_column] = name[1::]
                data_time_step = list(select_by_name_df[self.time_step_column])

                # IF there are missing time steps
                if set(time_steps) != set(data_time_step):
                    logger.info('Found missing time steps.')
                    for step in time_steps:
                        if step not in data_time_step:
                            row = {field: 0 for field in list(df.columns)}
                            row[self.time_step_column] = step
                            if contain_space:
                                row[self.group_by_column] = name[1::]
                            else:
                                row[self.group_by_column] = name
                        else:
                            row = select_by_name_df.query(f'{self.time_step_column} == {step}').to_dict('records')[0]
                        data.append(row)
                else:
                    logger.info('No missing time steps.')
            return data

        except Exception as e:
            app_settings.error_log(logger, e)

    def checkTimeSteps(self):
        """
        Runs methods and output CSV file.
        """
        try:
            logger.info('Add missing time steps.')
            is_csv = os.path.basename(self.csv_log_file).endswith('.csv')

            # Check the input file is CSV file and it exists.
            if is_csv and os.path.exists(self.csv_log_file):
                df = pd.read_csv(self.csv_log_file)
                df = df.loc[:, ~df.columns.str.contains('^Unnamed')]  # Remove empty columns
                time_steps = [i for i in range(self.min_time, self.max_time + self.time_interval, self.time_interval)]

                if self.group_by_column is not None:  # IF groupby parameter is given
                    data = self.add_time_steps_groupby(df, time_steps)
                else:
                    # Call
                    data = self.add_time_steps(df, time_steps)

                self.out_csv(data)  # Write to CSV file
            else:
                raise FileNotFoundError

        except FileNotFoundError:
            logger.error(f'{self.csv_log_file} does not exist.')
        except Exception as e:
            app_settings.error_log(logger, e)
